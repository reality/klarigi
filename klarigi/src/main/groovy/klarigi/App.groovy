/*
 * This Groovy source file was generated by the Gradle 'init' task.
 */
package klarigi

// Todo, replace this with non-deprecated version
import groovy.cli.picocli.CliBuilder
import org.semanticweb.owlapi.util.*

class App {
  static void main(String[] args) {
    def o = App.BuildOptions(args) 

    // Now we will run Klarigi 
    def k = new Klarigi(o)

    if(o['similarity-mode']) {
      k.genSim()
      System.exit(0)
    }

    // The business

    def allExplanations = o['group'] ? k.explainClusters(o['groups']) : k.explainAllClusters()

    // We only wanted the scores, so now we exit
    if(o['scores-only']) {
      println "Done (scores-only)."
      System.exit(0)
    }

    // Permutation testing
    def pVals = [:]
    if(o['perms']) {
      if(o['egl']) { 
        println 'Skipping permutation testing because in EGL mode.'
      } else {
        pVals = k.permutationTest(allExplanations)
      }
    }

    allExplanations.each {
      k.output(it.cluster, it.results, pVals[it.cluster])
    }

    // Optionally output a dataframe
    if(o['output-exp-dataframe']) {
      k.writeDataframe('train', allExplanations)
    }
      
    // Reclassification and classification
    if(o['egl']) { 
      println 'Skipping classification options because in EGL mode.'
    } else {
      if(o['reclassify']) {
        k.reclassify(allExplanations)
      }
      if(o['classify']) {
        k.classify(allExplanations)

        if(o['output-exp-dataframe']) {
          k.writeDataframe('test', allExplanations)
        }
      }
    }
  }

  static def BuildOptions(args) {
    def cliBuilder = new CliBuilder(
      usage: 'klarigi [<options>]',
      header: 'Options:'
    )

    cliBuilder.with {
      h longOpt: 'help', 'Print this help text and exit.'

      _ longOpt: 'similarity-mode', 'Calculate semantic similarity instead of characterising groups', type: Boolean

      d longOpt: 'data', 'The data describing entities and associations. See documentation for format.', args: 1
      pp longOpt: 'pp', 'Enable phenopacket input mode. If this is enabled, the --data argument should be either a single phenopacket JSON file, or a directory, from which all phenopacket JSON files will be read.', type: Boolean
      o longOpt: 'ontology', 'The ontology to use for explanations (should be the same as the ontology used to describe patients).', args: 1
      _ longOpt: 'turtle', 'Indicates that the ontology is a Turtle ontology (needed for calculating IC...)', type: Boolean

      _ longOpt: 'exclude-classes', 'A semi-colon delimited list of IRIs to exclude from scoring (and thus inclusion in explanations). Their subclasses will also be discluded.', args: 1

      ri longOpt: 'resnik-ic', 'Use Resnik annotation frequency for information content calculation', type: Boolean
      ic longOpt: 'ic', 'List of classes and associated information content values.', args: 1
      _ longOpt: 'save-ic', 'Save the IC values to the given file', args:1

      g longOpt: 'group', 'The group to explain.', args: 1
      egl longOpt: 'exclusive-group-load', 'If set to true, only the group given in -g will be loaded into the corpus', type: Boolean
      gf longOpt: 'group-file', 'You can pass a file with a list of groups to: one per line. If you do this, the --group argument will be ignored.', args: 1

      _ longOpt: 'top-ic', 'Max IC to use in stepdown algorithm. Default: 0.8', args: 1
      _ longOpt: 'bot-ic', 'Min IC to use in stepdown algorithm. Default: 0.4', args: 1
      _ longOpt: 'top-inclusion', 'Max inclusion to use in stepdown algorithm. Default: 0.95', args: 1
      _ longOpt: 'bot-inclusion', 'Min inclusion to use in stepdown algorithm. Default: 0.3', args: 1
      _ longOpt: 'top-exclusion', 'Max exclusion to use in stepdown algorithm. Default: 0.95', args: 1
      _ longOpt: 'bot-exclusion', 'Min exclusion to use in stepdown algorithm. Default: 0.3', args: 1
      _ longOpt: 'top-total-inclusion', 'Max total inclusion to use in stepdown algorithm. Default: 0.95 (probably don\'t want to edit this one)', args: 1
      _ longOpt: 'bot-r-score', 'Min acceptable value of r-score for stepdown algorithm.', args: 1

      _ longOpt: 'min-exclusion', 'Candidate restriction: Terms with exclusion below this level will not be considered for explanations.', args: 1
      _ longOpt: 'min-inclusion', 'Candidate restriction: Terms with inclusion below this level will not be considered for explanations.', args: 1
      _ longOpt: 'min-r-score', 'Candidate restriction: Terms with r-score below this level will not be considered for explanations.', args: 1
      _ longOpt: 'min-ic', 'Candidate restriction: Terms with IC below this level will not be considered for explanations.', args: 1

      _ longOpt: 'include-all', 'Ignore all min scores', type: Boolean

      _ longOpt: 'max-exclusion', 'Variables with exclusion higher than this will not count to total overall inclusion in the stepdown algorithm. They will, however, still appear in explanations.', args: 1
      _ longOpt: 'max-inclusion', 'Variables with inclusion higher than this will not count to total overall inclusion in the stepdown algorithm. They will, however, still appear in explanations.', args: 1

      _ longOpt: 'step', 'Step by which to reduce coefficients in stepdown algorithm. Default: 0.05', args: 1
      _ longOpt: 'debug', 'Print some debug output', type: Boolean

      _ longOpt: 'scores-only', 'Do not run StepDown algorithm. Useful if you only want to save scores.', type: Boolean
      _ longOpt: 'reclassify', 'Attempt to reclassify the input using the derived explanations. This will help give some scores about how well the explanations fit the data', type: Boolean
      _ longOpt: 'classify', 'Pass a new file of unseen examples to classify using the explanations derived (test classify)', args: 1
      ucm longOpt: 'univariate-classify-mode', 'Use the larger set of univariate results for classification tasks. Note: this is overriden when using --classify-with-variables.', type: Boolean
      _ longOpt: 'classify-with-variables', 'Instead of using Klarigi\'s results to (re)-classify with, use the terms specified in the given file. The file should be a two-column TSV. First column is a term ID, the second is the group association (group this variable should be used to explain).', args: 1

      p longOpt: 'perms', 'Do permutation testing to provide p values for inclusion, and exclusion.', args: 1, type: Integer

      _ longOpt: 'output-scores', 'Output the results of the scorer. This can be useful for debugging, or identifying coefficient settings.', type: Boolean
      _ longOpt: 'output-type', 'Pass either "latex" or "tsv" to output as LaTeX table format or TSV format respectively.', args: 1
      _ longOpt: 'output-classification-scores', 'Output classification scores and true/false labels for each group into files. Useful for generating AUCs.', type: Boolean
      _ longOpt: 'output-exp-dataframe', "Output a TSV describing a 'data-frame' of categorical values for each term appearing in derived explanations. Easy to load into R and do stuff with.", type: Boolean

      _ longOpt: 'threads', 'Number of threads to use, particularly for calculating scoring. This should speed things up a lot with larger datasets.', type: Integer

      _ longOpt: 'output', 'File to output results to. If not given, will print to stdout', args: 1
      _ longOpt: 'print-members', 'Print members of groups by label (first column of data file). Only works with standard output (not LaTeX)', type: Boolean

      _ longOpt: 'verbose', 'Verbose output, mostly progress', type: Boolean, args: 0
    }

    if(args.size() == 0 || (args.size() > 0 && (args[0] == '-h' || args[0] == '--help'))) {
      cliBuilder.usage(); 
      System.exit(0)
    }
    
    SLF4JSilencer.silence();

    def parsedOptions = cliBuilder.parse(args)
    if(!parsedOptions || (parsedOptions && parsedOptions.h)) { 
      cliBuilder.usage(); 
      System.exit(0)
    }

    def o = parsedOptions.matchedOptions().collectEntries { a ->
      a = a.names().last().replace('--', '')
      [(a): parsedOptions[a]]
    }

    // For some reason, the required bit doesn't work above. Stupid.
    def REQUIRED_OPTIONS = [ 'data', 'ontology' ]
    def missingOptions = false
    REQUIRED_OPTIONS.each {
      if(!o[it] || o[it] == '') {
        println "Error: You must pass a $it option. See -h for more info about parameters."
        missingOptions = true
      }
    }
    if(missingOptions) { System.exit(1) }

    /*def threads = 1
    if(o['threads']) {
      try {
        o['threads'] = Integer.parseInt(o['threads'])
      } catch(e) {
        println 'Warning: Could not parse --threads argument. Defaulting to 1.'
        o['threads'] = 1
      }
    }*/
    if(!o['threads']) {
      o['threads'] = Runtime.getRuntime().availableProcessors() + 1
    }

    if(o['exclude-classes']) {
      o['exclude-classes'] = o['exclude-classes'].tokenize(';')
      if(o['exclude-classes'].size() > 0 && o['exclude-classes'][0] =~ /:/ && o['exclude-classes'][0].indexOf('http') == -1) { // stupid
          o['exclude-classes'] = o['exclude-classes'].collect { 
            'http://purl.obolibrary.org/obo/' + it.replace(':', '_')
          }
      }
    }

    if(o['classify-with-variables']) { 
      o['univariate-classify-mode'] = false
    }

    // Otherwise, variables we use to classify may not be scored (and we need their old nExclusion values). Strictly it should probably be on CWV rather than c and re?
    if(o['classify']) {
      o['include-all'] = true
  }

    // TODO kind of stupid
    if(o['group-file']) {
      try {
        o['group'] = new File(o['group-file']).text.split('\n')
      } catch(e) {
        println "Could not handle the --group-file: ${e.toString()}"
        System.exit(1)
      }
    } else if(o['group'] =~ ';') {
      o['group'] = o['group'].tokenize(';')
    } else if(o['group']) {
      o['group'] = [o['group']]
    } else {
      o['group'] = []
    }

    return o;
  }
}
